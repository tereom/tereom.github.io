```{r setup, include=FALSE, message=FALSE, warning=FALSE}
library(tidyverse)
knitr::opts_chunk$set(
    comment = "#>",
    collapse = TRUE,
    fig.align = "center"
)
comma <- function(x) format(x, digits = 2, big.mark = ",")
ggplot2::theme_set(ggplot2::theme_minimal())
```


## Datos limpios

Una vez que importamos datos a R es conveniente limpiarlos, esto implica 
almacenarlos de una manera consisistente que nos permita enfocarnos en responder 
preguntas de los datos en lugar de estar luchando con los datos. 

Datos limpios son datos que facilitan las tareas del análisis de datos: 

*  **Visualización**: Resúmenes de datos usando gráficas, análisis exploratorio, 
o presentación de resultados. 

* **Manipulación**: Manipulación de variables como agregar, filtrar, reordenar,
transformar. 

* **Modelación**: Ajustar modelos es sencillo si los datos están en la forma 
correcta.

<div class="caja">
Los **principios de los datos limpios** [@tidy] 
proveen una manera estándar de organizar la información:

1. Cada columna es una variable.
2. Cada renglón es una observación .
3. Cada celda es un único valor.
</div>

Vale la pena notar que los principios de los datos limpios se pueden ver como 
teoría de algebra relacional para estadísticos, estós principios junto con 
*cada tipo de unidad observacional forma una tabla* equivalen a 
[la tercera forma normal de Codd](https://en.wikipedia.org/wiki/Third_normal_form) 
con enfoque en una sola tabla de datos en lugar de muchas conectadas en bases de 
datos relacionales. 

Veamos un ejemplo:

La mayor parte de las bases de datos en estadística tienen forma rectangular, 
¿cuántas variables tiene la siguiente tabla?

<div class="mi-tabla">
|   |tratamientoA|tratamientoB
----|------------|---------
Juan Aguirre|-   |2
Ana Bernal  |16  |11
José López  |3   |1
</div>

La tabla anterior también se puede estructurar de la siguiente manera:

<div class="mi-tabla">
 ||Juan Aguirre| Ana Bernal|José López
--|------------|-----------|----------
tratamientoA|- |    16     |   3
tratamientoB|2 |    11     |   1
</div>

Si vemos los principios (cada variable forma una columna, cada observación 
forma un renglón, cada tipo de unidad observacional forma una tabla), ¿las 
tablas anteriores cumplen los principios?


Para responder la pregunta identifiquemos primero cuáles son las variables y 
cuáles las observaciones de esta pequeña base. Las variables son: 
persona/nombre, tratamiento y resultado. Entonces, siguiendo los principios de
_datos limpios_ obtenemos la siguiente estructura: 

<div class="mi-tabla">
nombre      |tratamiento|resultado
------------|-----|---------
Juan Aguirre|a    |-
Ana Bernal  |a    |16
José López  |a    |3
Juan Aguirre|b    |2
Ana Bernal  |b    |11
José López  |b    |1
</div>

### Limpieza bases de datos {-}

Los principios de los datos limpios parecen obvios pero la mayor parte de los 
datos no los cumplen debido a:

1. La mayor parte de la gente no está familiarizada con los principios y es 
difícil derivarlos por uno mismo.  
2. Los datos suelen estar organizados para facilitar otros aspectos que no son 
análisis, por ejemplo, la captura.  

Algunos de los problemas más comunes en las bases de datos que no están 
_limpias_ son:

* Los encabezados de las columnas son valores y no nombres de variables. 
* Más de una variable por columna. 
* Las variables están organizadas tanto en filas como en columnas. 
* Más de un tipo de observación en una tabla.
* Una misma unidad observacional está almacenada en múltiples tablas. 

La mayor parte de estos problemas se pueden arreglar con pocas herramientas, 
a continuación veremos como _limpiar_ datos usando 2 funciones del paquete 
`tidyr`:

* **gather**: recibe múltiples columnas y las junta en pares de valores y 
nombres y alarga los datos.  

* **spread**: recibe 2 columnas y las separa, haciendo los datos más anchos.

Repasaremos los problemas más comunes que se encuentran en conjuntos de datos
sucios y mostraremos como se puede manipular la tabla de datos (usando las 
funciones *gather* y *spread*) con el fin de estructurarla para que cumpla los
principios de datos limpios.

### Los encabezados de las columanas son valores {-}

Usaremos ejemplos para entender los conceptos más facilmente. Comenzaremos
con una tabla de datos que contiene las mediciones de partículas suspendidas
PM2.5 de la red automática de monitoreo atmosférico 
([RAMA](http://www.aire.cdmx.gob.mx)) para los primeros meses del 2019.

```{r}
library(tidyverse)
library(estcomp)
pm25_2019
```

¿Cuáles son las variables en estos datos?

Esta base de datos tiene 4 variables: fecha, hora, estación y medición 
(en microgramos por metro cúbico $\mu g/m^3$). 

Al alargar los datos desaparecerán las columnas que se agrupan y darán 
lugar a dos nuevas columnas: la correspondiente a estación y la 
correspondiente a medición. Entonces,  usamos la función `gather()` que 
recibe los argumentos:

* data: base de datos que vamos a reestructurar.  
* key: nombre de la nueva variable que contiene lo que fueron los nombres
de columnas que apilamos.  
* value: nombre de la variable que almacenará los valores que corresponden a 
cada *key*.  
* ...: lo último que especificamos son las columnas que vamos a apilar, la 
notación para seleccionarlas es la misma que usamos con `select()`.

```{r}
pm25_2019_tidy <- gather(pm25_2019, key = station, value = measurement, -date, 
  -hour)
head(pm25_2019_tidy)
tail(pm25_2019_tidy)
```

Observemos que en la tabla original teníamos bajo la columna *AJM*, en el 
renglón correspondiente a *2019-01-01* hora *1* un valor de 19, y podemos ver 
que este valor en la tabla larga se almacena bajo la columna *measurement* y 
corresponde a la estación *AJM*.

La nueva estructura de la base de datos nos permite, por ejemplo, hacer 
fácilmente una gráfica donde podemos comparar las diferencias en las 
frecuencias. 

```{r}
pm25_2019_tidy %>% 
    mutate(
        missing = is.na(measurement), 
        station = reorder(station, missing, sum)
        ) %>% 
    ggplot(aes(x = date, y = hour, fill = is.na(measurement))) +
    geom_raster(alpha = 0.8) +
    facet_wrap(~ station) +
    scale_fill_manual("faltante", 
        values = c("TRUE" = "salmon", "FALSE" = "gray"))
```

Otro ejemplo, veamos los datos `df_edu`, ¿cuántas variables tenemos?

```{r}
df_edu
```

Notemos que el nivel de escolaridad esta guardado en 6 columnas (preschool,
elementary, ..., other), este tipo de almacenamiento *no es limpio* aunque 
puede ser útil al momento de ingresar la información o para presentarla.

Para tener datos *limpios* apilamos los niveles de escolaridad de manera que 
sea una sola columna (nuevamente alargamos los datos):

```{r}
df_edu_tidy <- gather(data = df_edu, grade, percent, preschool:other, 
  na.rm = TRUE)
glimpse(df_edu_tidy)
```

El parámetro `na.rm = TRUE` se utiliza para eliminar los renglones con valores 
faltantes en la columna de porcentaje, esto es, eliminamos aquellas 
observaciones que tenían `NA` en la columnas de nivel de escolaridad de la tabla 
ancha. En este caso optamos por que los faltantes sean implícitos, la
conveniencia de tenerlos implícitos/explícitos dependerá de la aplicación.

Con los datos limpios es facil hacer manipulaciones y grfiacs, ¿cómo habrían 
hecho la siguiente gráfica antes de la limpieza?

```{r}
df_edu_cdmx <- df_edu_tidy %>% 
    filter(state_abbr == "CDMX", sex != "Total", grade != "other") %>% 
    mutate(municipio_name = reorder(municipio_name, percent, last))

ggplot(df_edu_cdmx, aes(x = grade, 
    y = percent, group = sex, color = sex)) +
    geom_path() + 
    facet_wrap(~municipio_name) +
    theme(axis.text.x = element_text(angle = 60, hjust = 1)) +
    scale_x_discrete(limits = c("preschool", "elementary", 
        "secondary", "highschool", "higher_edu"))
```


### Una columna asociada a más de una variable {-}

Utilizaremos un subconjunto de los datos de la prueba ENLACE a nivel primaria,
la prueba [ENLACE](http://www.enlace.sep.gob.mx/ba/) evaluaba a todos los 
alumnos de tercero a sexto de primaria y a los alumnos de secundaria del país en 
3 áreas: *español*, *matemáticas* y *formación cívica y ética*.

```{r}
data("enlacep_2013")
enlacep_sub_2013 <- enlacep_2013 %>% 
    select(CVE_ENT:PUNT_FCE_6) %>% 
    sample_n(1000)
glimpse(enlacep_sub_2013)
```

![](imagenes/manicule2.jpg) ¿Cuántas variables tiene este subconjunto de los 
datos?

* De manera similar a los ejemplos anteriores, utiliza la función `gather()` 
para apilar las columnas correspondientes a área-grado.

```{r}
enlacep_long <- gather(enlacep_sub_2013, AREA_GRADO, PUNTAJE, 
    contains("PUNT"), na.rm = TRUE)
enlacep_long
```


* Piensa en como podemos separar la "variable" área-grado en dos columnas. 

Ahora separaremos las variables área y grado de la columna  `AREA_GRADO`, 
para ello debemos pasar a la función `separate()`, esta recibe como parámetros:  

- el nombre de la base de datos,  

- el nombre de la variable que deseamos separar en más de una,  

- la posición de donde deseamos "cortar" (hay más opciones para especificar 
como separar, ver `?separate`). El default es separar valores en todos los 
lugares que encuentre un caracter que no es alfanumérico (espacio, guión,...).

```{r}
enlacep_tidy <- separate(data = enlacep_long, col = AREA_GRADO, 
    into = c("AREA", "GRADO"), sep = 9)
enlacep_tidy

# creamos un mejor código de área
enlacep_tidy <- enlacep_tidy %>% 
    mutate(
        AREA = substr(AREA, 6, 8),
        GRADO = as.numeric(GRADO)
        ) 
glimpse(enlacep_tidy)
```

### Variables almacenadas en filas y columnas {-}

El problema más difícil es cuando las variables están tanto en filas como en 
columnas, veamos una base de datos de fertilidad. ¿Cuáles son las 
variables en estos datos?

```{r}
data("df_fertility")
df_fertility
```

Estos datos tienen variables en columnas individuales (state, size_localidad), 
en múltiples columnas (grupo de edad, age_15_19,..) y en filas (Valor y 
Error estándar). 

Comencemos por apilar las columnas.

```{r}
fertility_long <- gather(df_fertility, age_bracket, value, age_15_19:global, 
    na.rm = TRUE)
fertility_long
```

Podemos crear algunas variables adicionales.

```{r}
fertility_vars <- fertility_long %>% 
    mutate(
        state_code = str_sub(state, 1, 2), 
        state_name = str_sub(state, 4)
        ) %>%
    select(-state)
fertility_vars
```

Finalmente, la columna *est* no es una variable, sino que almacena el nombre 
de 2 variables: *Valor* y *Error Estándar* la operación que debemos aplicar 
(`spread()`) es el inverso de apilar (`gather`), sus argumentos son:

* data: `data.frame` que vamos a ensanchar.  
* key: nombre o posición de la columna cuyos valores se convertirán en nombres
de columnas.
* value: nombre o posición de la columna cuyos valores rellenarán las celdas
de las nuevas columnas.


```{r}
fertility_tidy <- spread(data = fertility_vars, key = est, value = value)
```

Y podemos mejorar los nombres de las columnas, una opción rápida es usar el 
paquete janitor.

```{r}
fertility_tidy %>% 
    janitor::clean_names() %>% 
    glimpse()
```

o podemos hacerlo manualmente

```{r}
names(fertility_tidy)[5:6] <- c("est", "std_error")
```

Ahora es inmediato no solo hacer gráficas sino también ajustar un modelo.

```{r}
# ajustamos un modelo lineal donde la variable respuesta es temperatura 
# máxima, y la variable explicativa es el mes
fertility_sub <- filter(fertility_tidy, age_bracket != "global")
fertility_lm <- lm(est ~ age_bracket, data = fertility_sub)
summary(fertility_lm)
```

Vale la pena notar que aunque los datos limpios facilitan las 
tareas de análisis, distintas funciones o tareas requieren los datos en 
distintos formas y saber reestructurar las tablas es indispensable para tener
flexibilidad, por ejemplo, al graficar.

![](imagenes/manicule2.jpg) Grafica el valor estimado de fertilidad del grupo de
edad 20-24 contra 25-29. ¿Qué transformación debes hacer? Tip: elimina la 
columna que corresponde al error estándar antes de ensanchar los
datos.

```{r, include=FALSE}
fertility_age <- spread(select(fertility_tidy, -std_error), age_bracket, est)

ggplot(fertility_age, aes(age_20_24, age_25_29, color = size_localidad)) +
  geom_abline(alpha = 0.5) +
  geom_point()
```

### Una misma unidad observacional está almacenada en múltiples tablas {-}

También es común que los valores sobre una misma unidad observacional estén 
separados en muchas tablas o archivos, es común que estas tablas esten divididas 
de acuerdo a una variable, de tal manera que cada archivo representa a una 
persona, año o ubicación. Para juntar los archivos hacemos lo siguiente:

1. Enlistamos las rutas de los archivos. 
2. Leemos cada archivo y agregamos una columna con el nombre del archivo. 
3. Combinamos las tablas en un solo data frame.  

Veamos un ejemplo, descargamos la carpeta con los datos de varios contaminantes
de RAMA,

```{r, eval=FALSE}
usethis::use_zip("https://github.com/tereom/estcomp/raw/master/data-raw/19RAMA.zip", 
    "data")
```

ésta contiene 9 archivos de excel que almacenan información de monitoreo de 
contaminantes. Cada archivo contiene información de un contaminante y el nombre
del archivo indica el contaminante. 

Los pasos en R (usando el paquete `purrr`), primero creamos un vector con los
nombres de los archivos en un directorio, eligiendo aquellos que contengan las
letras ".csv".

```{r, echo=FALSE, eval=FALSE}
library(here)
dir_rama <- here("data", "19RAMA")
paths <- dir(dir_rama, pattern = "\\.xls$", full.names = TRUE) 
paths
```

```{r}
paths <- dir("data/19RAMA", pattern = "\\.xls$", full.names = TRUE)
```

Después le asignamos el nombre del archivo al nombre de cada elemento del vector.
Este paso se realiza para preservar los nombres de los archivos ya que estos
los asignaremos a una variable mas adelante.

```{r}
paths <- set_names(paths, basename(paths))
```

La función `map_df` itera sobre cada dirección, lee el archivo excel de dicha 
dirección y los combina en un data frame.

```{r, error=TRUE}
library(readxl)
rama <- map_df(paths, read_excel, .id = "FILENAME")

# eliminamos la basura del id
rama <- rama %>%
  mutate(PARAMETRO = str_remove(FILENAME, "2019") %>% str_remove(".xls")) %>%
  select(PARAMETRO, FECHA:AJU)
# y apilamos para tener una columna por estación
rama_tidy <- rama %>%
    gather(estacion, valor, ACO:AJU) %>% 
    mutate(valor = ifelse(-99, NA, valor))
rama_tidy
    
```

### Otras consideraciones {-}

En las buenas prácticas es importante tomar en cuenta los siguientes puntos:

* Incluir un encabezado con el nombre de las variables.

* Los nombres de las variables deben ser entendibles (e.g. AgeAtDiagnosis es 
mejor que AgeDx).

* En general los datos se deben guardar en un archivo por tabla.

* Escribir un script con las modificaciones que se hicieron a los _datos crudos_ 
(reproducibilidad).

* Otros aspectos importantes en la _limpieza_ de datos son: selección del tipo 
de variables (por ejemplo fechas), datos faltantes, _typos_ y detección de 
valores atípicos.


### Recursos adicionales {-}

* [Data Transformation Cheat Sheet](https://github.com/rstudio/cheatsheets/raw/master/data-transformation.pdf), 
RStudio.

* Limpiar nombres de columnas, eliminar filas vacías y más, paquete 
[janitor](https://github.com/sfirke/janitor).

* Lectura de datos tabulares con distintas estructuras, paquete 
[tidycells](https://buff.ly/2z9CcBN).



